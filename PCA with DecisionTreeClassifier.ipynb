{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75727936, 0.1871838 , 0.04843649, 0.00710035])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "iris=load_iris()\n",
    "\n",
    "dataset = pd.DataFrame({\n",
    "    'sepal_length':iris.data[:,0],\n",
    "    'sepal_width':iris.data[:,1],\n",
    "    'petal_length':iris.data[:,2],\n",
    "    'petal_width':iris.data[:,3],\n",
    "    'Class':iris.target\n",
    "})\n",
    "\n",
    "X = dataset.drop('Class',axis=1)\n",
    "y = dataset['Class']\n",
    "\n",
    "'''\n",
    "df = pd.read_csv('wt-ht.csv')\n",
    "X = df.drop(['Gender','Height'],axis=1) # Stored wt and ht in X by dropping Class\n",
    "# Dropping Height and Weight each iteratively decreases and increases the accuracy score\n",
    "y = df['Gender'] # Storing only Class\n",
    "'''\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler # To Scale down the values based on their Mean\n",
    "sc = StandardScaler() # Mean is calculated and X,Y (0,0) are converted based on the mean vals\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "x_train = pca.fit_transform(X_train)\n",
    "x_test = pca.fit_transform(X_test)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "explained_variance # Here the significance of each component is shown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[11,  0,  0],\n",
       "       [ 0, 13,  0],\n",
       "       [ 0,  0,  6]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "PCA Transformed values are passed to DecisionTreeClassifier which collectively gives importance to more weightage columns\n",
    "If you want you can drop the columns from dataset which have less weightage\n",
    "'''\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sklearn.metrics as metrics\n",
    "classifier = DecisionTreeClassifier() # DecisionTreeClassifier is a class and we are making an instance of it\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print('Accuracy',metrics.accuracy_score(y_test,y_pred))\n",
    "metrics.confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
